[
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data",
    "section": "",
    "text": "Link To Dataset\nThis dataset was collected by ProPublica in 2013 and 2014 from the Broward County Sheriff’s Office in Florida and contains 11,757 individuals’ COMPAS (Correctional Offender Management Profiling for Alternative Sanctions) scores. The COMPAS score is calculated via a computerized algorithm and is a metric commonly used by judges and officers to determine the likelihood of someone re-offending (recidivism). This data was originally collected by ProPublica to analyze and determine the presence of racial biases across the scores.\n\n\n\nWithin the GitHub repository there are several data files. For the purposes of our analysis, we will only be focusing on the compas-scores-raw.csv file which contains the raw data obtained by ProPublica via a public records request. This file contains 28 variables. Of these 28, we have determined that we will be focusing on the following 8:\n\nindividual_ID: The unique identifier for each individual\nSex_Code_Text: Indicates the individual’s sex. We have re-coded this variable to Sex in the cleaned dataset.\nEthnic_Code_Text: Indicates a individual’s ethnicity. Possible values are Caucasian, African-American, Hispanic, Other, Asian, and African-Am. We have recoded this variable to Race in the cleaned dataset.\nDateOfBirth: Indicates the individual’s date of birth\nAge: The individual’s age, calculated from DOB during data cleaning.\nRawScore: The individual’s raw COMPAS score. This is the raw score generated by the COMPAS algorithm and, in this dataset, ranges from -4.79 to 51.\nDecileScore: The individual’s decile compas score. This score is generated by ranking individuals by their raw scores, dividing this ranked list into ten equal parts (deciles), and assigning a score from 1 to 10 to each individual based on the decile they fall into, effectively categorizing them into relative risk levels.\nScoreText: The individual’s categorized recidivism risk. Either Low, Medium, High, or N/A.\n\n\n\n\nBelow is the data cleaning script\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(dplyr)      # For attribute selection\nlibrary(lubridate)  # For calculating COMPAS person's age\n\ncompas_data &lt;- read_csv(here::here(\"dataset\", \"compas-scores-raw.csv\"))\n\nRows: 60843 Columns: 28\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (18): Agency_Text, LastName, FirstName, MiddleName, Sex_Code_Text, Ethni...\ndbl (10): Person_ID, AssessmentID, Case_ID, ScaleSet_ID, RecSupervisionLevel...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n## Clean the data\n\n# Calculate age based on DateOfBirth and Screening_Date\n# Convert date strings to Date objects\ncompas_data$DateOfBirth &lt;- mdy(compas_data$DateOfBirth)\ncompas_data$Screening_Date &lt;- mdy_hm(compas_data$Screening_Date)\n\ncompas_data$Age &lt;- as.numeric(difftime(compas_data$Screening_Date, compas_data$DateOfBirth, units = \"days\") / 365.25)\n\ncompas_data_clean &lt;- compas_data %&gt;%\n  select(Person_ID, Sex = Sex_Code_Text, Race = Ethnic_Code_Text, DateOfBirth, Age, RawScore, DecileScore, ScoreText) %&gt;% \n  drop_na()\n\nwrite_csv(compas_data_clean, file = here::here(\"dataset\", \"compas-scores-clean.csv\"))\n\nsave(compas_data_clean, file = here::here(\"dataset/compas-scores-clean.RData\"))\n\nThe above code:\n\nload the data from compas-scores-raw.csv in our dataset directory\nThen it tells R that DateOfBirth field follows mm/dd/yyyy format and Screening_Date follows mm/dd/yyyy hh:mm format using mdy and mdy_hm function from lubridate package.\nUsing the difference in days between DateOfBirth and Screening_Date, we can calculate the age of that person. We then save the age to a field called Age.\nThen using dplyr package, we project on only those fields that we think is useful to us and drop any triples with na values.\nWe save the clean data to compas-scores-clean.csv to our dataset directory."
  },
  {
    "objectID": "data.html#data-sources",
    "href": "data.html#data-sources",
    "title": "Data",
    "section": "",
    "text": "Link To Dataset\nThis dataset was collected by ProPublica in 2013 and 2014 from the Broward County Sheriff’s Office in Florida and contains 11,757 individuals’ COMPAS (Correctional Offender Management Profiling for Alternative Sanctions) scores. The COMPAS score is calculated via a computerized algorithm and is a metric commonly used by judges and officers to determine the likelihood of someone re-offending (recidivism). This data was originally collected by ProPublica to analyze and determine the presence of racial biases across the scores.\n\n\n\nWithin the GitHub repository there are several data files. For the purposes of our analysis, we will only be focusing on the compas-scores-raw.csv file which contains the raw data obtained by ProPublica via a public records request. This file contains 28 variables. Of these 28, we have determined that we will be focusing on the following 8:\n\nindividual_ID: The unique identifier for each individual\nSex_Code_Text: Indicates the individual’s sex. We have re-coded this variable to Sex in the cleaned dataset.\nEthnic_Code_Text: Indicates a individual’s ethnicity. Possible values are Caucasian, African-American, Hispanic, Other, Asian, and African-Am. We have recoded this variable to Race in the cleaned dataset.\nDateOfBirth: Indicates the individual’s date of birth\nAge: The individual’s age, calculated from DOB during data cleaning.\nRawScore: The individual’s raw COMPAS score. This is the raw score generated by the COMPAS algorithm and, in this dataset, ranges from -4.79 to 51.\nDecileScore: The individual’s decile compas score. This score is generated by ranking individuals by their raw scores, dividing this ranked list into ten equal parts (deciles), and assigning a score from 1 to 10 to each individual based on the decile they fall into, effectively categorizing them into relative risk levels.\nScoreText: The individual’s categorized recidivism risk. Either Low, Medium, High, or N/A.\n\n\n\n\nBelow is the data cleaning script\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(dplyr)      # For attribute selection\nlibrary(lubridate)  # For calculating COMPAS person's age\n\ncompas_data &lt;- read_csv(here::here(\"dataset\", \"compas-scores-raw.csv\"))\n\nRows: 60843 Columns: 28\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (18): Agency_Text, LastName, FirstName, MiddleName, Sex_Code_Text, Ethni...\ndbl (10): Person_ID, AssessmentID, Case_ID, ScaleSet_ID, RecSupervisionLevel...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n## Clean the data\n\n# Calculate age based on DateOfBirth and Screening_Date\n# Convert date strings to Date objects\ncompas_data$DateOfBirth &lt;- mdy(compas_data$DateOfBirth)\ncompas_data$Screening_Date &lt;- mdy_hm(compas_data$Screening_Date)\n\ncompas_data$Age &lt;- as.numeric(difftime(compas_data$Screening_Date, compas_data$DateOfBirth, units = \"days\") / 365.25)\n\ncompas_data_clean &lt;- compas_data %&gt;%\n  select(Person_ID, Sex = Sex_Code_Text, Race = Ethnic_Code_Text, DateOfBirth, Age, RawScore, DecileScore, ScoreText) %&gt;% \n  drop_na()\n\nwrite_csv(compas_data_clean, file = here::here(\"dataset\", \"compas-scores-clean.csv\"))\n\nsave(compas_data_clean, file = here::here(\"dataset/compas-scores-clean.RData\"))\n\nThe above code:\n\nload the data from compas-scores-raw.csv in our dataset directory\nThen it tells R that DateOfBirth field follows mm/dd/yyyy format and Screening_Date follows mm/dd/yyyy hh:mm format using mdy and mdy_hm function from lubridate package.\nUsing the difference in days between DateOfBirth and Screening_Date, we can calculate the age of that person. We then save the age to a field called Age.\nThen using dplyr package, we project on only those fields that we think is useful to us and drop any triples with na values.\nWe save the clean data to compas-scores-clean.csv to our dataset directory."
  },
  {
    "objectID": "analysis.html",
    "href": "analysis.html",
    "title": "MA 415 Final Project Team 5",
    "section": "",
    "text": "git — title: Analysis description: Here we provide a detailed analysis using more sophisticated statistics techniques. toc: true draft: false\nThis comes from the file analysis.qmd.\nWe describe here our detailed data analysis. This page will provide an overview of what questions you addressed, illustrations of relevant aspects of the data with tables and figures, and a statistical model that attempts to answer part of the question. You’ll also reflect on next steps and further analysis.\nThe audience for this page is someone like your class mates, so you can expect that they have some level of statistical and quantitative sophistication and understand ideas like linear and logistic regression, coefficients, confidence intervals, overfitting, etc.\nWhile the exact number of figures and tables will vary and depend on your analysis, you should target around 5 to 6. An overly long analysis could lead to losing points. If you want you can link back to your blog posts or create separate pages with more details.\nThe style of this paper should aim to be that of an academic paper. I don’t expect this to be of publication quality but you should keep that aim in mind. Avoid using “we” too frequently, for example “We also found that …”. Describe your methodology and your findings but don’t describe your whole process."
  },
  {
    "objectID": "analysis.html#note-on-attribution",
    "href": "analysis.html#note-on-attribution",
    "title": "MA 415 Final Project Team 5",
    "section": "Note on Attribution",
    "text": "Note on Attribution\nIn general, you should try to provide links to relevant resources, especially those that helped you. You don’t have to link to every StackOverflow post you used but if there are explainers on aspects of the data or specific models that you found helpful, try to link to those. Also, try to link to other sources that might support (or refute) your analysis. These can just be regular hyperlinks. You don’t need a formal citation.\nIf you are directly quoting from a source, please make that clear. You can show quotes using &gt; like this\n&gt; To be or not to be.\n\nTo be or not to be."
  },
  {
    "objectID": "analysis.html#rubric-on-this-page",
    "href": "analysis.html#rubric-on-this-page",
    "title": "MA 415 Final Project Team 5",
    "section": "Rubric: On this page",
    "text": "Rubric: On this page\nYou will\n\nIntroduce what motivates your Data Analysis (DA)\n\nWhich variables and relationships are you most interested in?\nWhat questions are you interested in answering?\nProvide context for the rest of the page. This will include figures/tables that illustrate aspects of the data of your question.\n\nModeling and Inference\n\nThe page will include some kind of formal statistical model. This could be a linear regression, logistic regression, or another modeling framework.\nExplain the ideas and techniques you used to choose the predictors for your model. (Think about including interaction terms and other transformations of your variables.)\nDescribe the results of your modelling and make sure to give a sense of the uncertainty in your estimates and conclusions.\n\nExplain the flaws and limitations of your analysis\n\nAre there some assumptions that you needed to make that might not hold? Is there other data that would help to answer your questions?\n\nClarity Figures\n\nAre your figures/tables/results easy to read, informative, without problems like overplotting, hard-to-read labels, etc?\nEach figure should provide a key insight. Too many figures or other data summaries can detract from this. (While not a hard limit, around 5 total figures is probably a good target.)\nDefault lm output and plots are typically not acceptable.\n\nClarity of Explanations\n\nHow well do you explain each figure/result?\nDo you provide interpretations that suggest further analysis or explanations for observed phenomenon?\n\nOrganization and cleanliness.\n\nMake sure to remove excessive warnings, hide most or all code, organize with sections or multiple pages, use bullets, etc.\nThis page should be self-contained, i.e. provide a description of the relevant data."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MA [46]15 Final Project",
    "section": "",
    "text": "Final Project due May 7, 2024 at 11:59pm.\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nBlog Post 4\n\n\nContinuing Exploratory Analysis\n\n\n\n\n\n\n\n\n\nApr 3, 2024\n\n\n\n\n\n\n  \n\n\n\n\nPost 3 Project Update\n\n\n4/1 Project Update\n\n\n\n\n\n\n\n\n\nMar 29, 2024\n\n\n\n\n\n\n  \n\n\n\n\nPost 2: Project Update\n\n\nData Background + Loading and Cleaning + Data for Equity\n\n\n\n\n\n\n\n\n\nMar 22, 2024\n\n\n\n\n\n\n  \n\n\n\n\nPost 1: Dataset Description\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 28, 2024\n\n\n\n\n\n\n  \n\n\n\n\nExamples\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 26, 2024\n\n\nDaniel Sussman\n\n\n\n\n\n\n  \n\n\n\n\nGetting started\n\n\n\n\n\n\n\n\n\n\nDirections to set up your website and create your first post.\n\n\n\n\n\n\nFeb 23, 2024\n\n\nDaniel Sussman\n\n\n\n\n\n\n  \n\n\n\n\nFirst Team Meeting\n\n\n\n\n\n\n\n\n\n\nThis post details the steps you’ll take for your first team meeting.\n\n\n\n\n\n\nFeb 21, 2024\n\n\nDaniel Sussman\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2024-03-22-post-2-project-update/post-2-project-update.html",
    "href": "posts/2024-03-22-post-2-project-update/post-2-project-update.html",
    "title": "Post 2: Project Update",
    "section": "",
    "text": "After discussion, we decided to choose the data set about COMPAS Recidivism Racial Bias. We took time to investigate the data, so we found the original source about the data. Then, we did data loading and cleaning. At last, we read the article on Data for Equity Principals and thought about how the data could be applied on our data. And, we wrote several paragraphs about limitations of your analysis and the potential for abuse or misuse of the data."
  },
  {
    "objectID": "posts/2024-03-22-post-2-project-update/post-2-project-update.html#data-equity",
    "href": "posts/2024-03-22-post-2-project-update/post-2-project-update.html#data-equity",
    "title": "Post 2: Project Update",
    "section": "Data Equity",
    "text": "Data Equity\nFor the COMPAS Recidivism Racial Bias dataset, equitable data practices are relevant mainly from two points: Beneficence and Transparence. The beneficence principle demands that the collection, analysis, and dissemination of data on probation recidivism actively aim to benefit the individuals and communities represented in the data. For this dataset, adhering to beneficence involves being meticulous in how recidivism data are analyzed and presented. This means ensuring that the analysis does not inadvertently stigmatize individuals based on race, ethnicity, or any other demographic characteristic. It also involves considering the potential policy implications of the findings and framing results in a way that highlights systemic solutions rather than individual failings. Transparency is crucial in discussing the dataset’s limitations and the context within which the data were collected and analyzed. Acknowledging the limitations in recidivism research, such as potential biases in the criminal justice system that affect who is under probation and the conditions of their supervision, is essential for responsible use of the data. Transparency about this dataset would involve openly discussing the potential for abuse or misuse of the data, such as the risk of the data being used to support policies that disproportionately affect marginalized communities. It also requires clear communication about the scope of the analysis, the assumptions made, and the measures taken to protect the privacy and dignity of individuals represented in the data. For instance, any analysis should be clear about its geographical and temporal scope, the definitions of success or failure in probation, and the inherent uncertainties in measuring and predicting recidivism. The analysis faces limitations that might not fully capture the complex factors influencing recidivism, such as access to support services and community reintegration programs. Additionally, there could be biases in data collection and reporting processes, reflecting systemic inequalities within the criminal justice system."
  },
  {
    "objectID": "posts/2023-10-13-first-team-meeting/first-team-meeting.html",
    "href": "posts/2023-10-13-first-team-meeting/first-team-meeting.html",
    "title": "First Team Meeting",
    "section": "",
    "text": "These are the steps that you will take today to get started on your project. Today, you will just be brainstorming, and then next week, you’ll get started on the main aspects of the project.\n\nStart by introducing yourselves to each other. I also recommend creating a private channel on Microsoft Teams with all your team members. This will be a place that you can communicate and share ideas, code, problems, etc.\nDiscuss what aspects of the project each of you are more or less excited about. These include\n\nCollecting, cleaning, and munging data ,\nStatistical Modeling,\nVisualization,\nWriting about analyses, and\nManaging and reviewing team work.\n\nBased on this, discuss where you feel your strengths and weaknesses might be.\nNext, start brainstorming questions you hope to answer as part of this project. This question should in some way be addressing issues around racial disparities. The questions you come up with should be at the level of the question we started with when exploring the HMDA data. (“Are there differences in the ease of securing a loan based on the race of the applicant?”) You’ll revise your questions a lot over the course of the project. Come up with a few questions that your group might be interested in exploring.\nBased on these questions, start looking around for data that might help you analyze this. If you are looking at U.S. based data, data.gov is a good source and if you are looking internationally, I recommend checking out the World Bank. Also, try Googling for data. Include “data set” or “dataset” in your query. You might even include “CSV” or some other format. Using “data” by itself in your query often doesn’t work too well. Spend some time searching for data and try to come up with at least three possible data sets. (For your first blog post, you’ll write short proposals about each of them that I’ll give feedback on.)\nCome up with a team name. Next week, I’ll provide the Github Classroom assignment that will be where you work on your final project and you’ll have to have your team name finalized by then. Your project will be hosted online at the website with a URL like sussmanbu.github.io/ma4615-fa23-final-project-TEAMNAME.\n\nNext time, you’ll get your final project website set up and write your first blog post."
  },
  {
    "objectID": "posts/2023-10-15-getting-started/getting-started.html",
    "href": "posts/2023-10-15-getting-started/getting-started.html",
    "title": "Getting started",
    "section": "",
    "text": "Below, the items marked with [[OP]] should only be done by one person on the team.\n\nTo get started\n\n[[OP]] One person from the team should click the Github Classroom link on Teams.\n[[OP]] That person types in the group name for their group.\nThe rest of the team now clicks the Github Classroom link and selects their team from the dropdown list.\nFinally, each of you can clone the repository to your laptop like a normal assignment.\n\n\n\nSetting up the site\n\n[[OP]] Open the terminal and run quarto publish gh-pages.\n[[OP]] Select Yes to the prompt:  ? Publish site to https://sussmanbu.github.io/ma4615-fa23-final-project-TEAMNAME/ using gh-pages? (Y/n)\n[[OP]] Wait for the process to finish.\nOnce it is done, you can go to the URL it asked you about to see your site.\n\nNote: This is the process you will use every time you want to update your published site. Make sure to always follow the steps below for rendering, previewing, and committing your changes before doing these publish steps. Anyone can publish in the future.\n\n\nCustomize your site\n\n[[OP]] Open the _quarto.yml file and update the title to include your team name.\n[[OP]] Go to the about.qmd and remove the TF’s and professor’s names.\nadd your own along with a short introduction and a link to your Github user page.\n[[OP]] Render the site.\n[[OP]] Check and make sure you didn’t get any errors.\n[[OP]] Commit your changes and push.\n[[OP]] Repeat the steps under Setting up your site.\n\nOnce one person is done with this, each teammate in the group can, in turn, repeat steps 3-7. Before doing so, make sure to pull the changes from teammates before starting to make new changes. (We’ll talk soon about ways to organize your work and resolve conflicts.)\n\n\nStart your first post\n\nTo start your first post first, run remotes::install_github(\"sussmanbu/quartopost\") in your Console.\n[[OP]] Run quartopost::quartopost() (or click Addins-&gt;Create Quarto Post, or use C-Shift-P, type “Create Quarto” and press enter to run the command).\n\nNow you can start working on your post. You’ll want to render your post to see what it will look like on the site.\n\nEvery time you want to make a new post, you can repeat step 2 above.\nWhen you want to publish your progress, follow steps 4-7 from Customize your site.\n\nFinally, make sure to read through everything on this site which has the directions and rubric for the final project."
  },
  {
    "objectID": "posts/2024-03-29-post-3-project-update/post-3-project-update.html",
    "href": "posts/2024-03-29-post-3-project-update/post-3-project-update.html",
    "title": "Post 3 Project Update",
    "section": "",
    "text": "In this week, we spent some extra time investigating the original data source, and summarized on the data background. We further analyzed on the data in our dataset. We analyzed the distribution of two important variable in our dataset which is “Raw Score” and the “Decile Score”. The “Raw Score” is the original score of individual’s likelyhood to conduct recidivism. The higher the score reflects that the person has a greater chance to reoffend. The “Decile Score” is the score calculated based on the commercial algorithm COMPAS (Correctional Offender Management Profiling for Alternative Sanctions). COMPAS scores for each defendant ranged from 1 to 10, with ten being the highest risk. Scores 1 to 4 were labeled by COMPAS as “Low”; 5 to 7 were labeled “Medium”; and 8 to 10 were labeled “High.”"
  },
  {
    "objectID": "posts/2024-03-29-post-3-project-update/post-3-project-update.html#data-background",
    "href": "posts/2024-03-29-post-3-project-update/post-3-project-update.html#data-background",
    "title": "Post 3 Project Update",
    "section": "Data Background",
    "text": "Data Background\nThis dataset is collected by ProPublica in 2013 and 2014, from the Broward County Sheriff’s Office in Florida. COMPAS is biased in favor of white defendants, and against black inmates. We are able to find the data from the original source.\nThere are no issues we can see with how the data was collected. The sample population is from criminal defendants in Broward County, Florida. Moreover, there exists some outliers, which will make the sample biased.\nThe data can be used to analyze the COMPAS recidivism algorithm. Also, the research “machine bias” is based on the same data. This data is used for some policy decisions. The COMPAS tool has been used by judges and parole officers to assess the likelihood of a defendant re-offending. Others asked whether the COMPAS algorithm exhibit racial bias in its predictions."
  },
  {
    "objectID": "posts/2024-03-29-post-3-project-update/post-3-project-update.html#data-analyze",
    "href": "posts/2024-03-29-post-3-project-update/post-3-project-update.html#data-analyze",
    "title": "Post 3 Project Update",
    "section": "Data Analyze",
    "text": "Data Analyze\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ncompas_scores_clean &lt;- read_csv(\"dataset/compas-scores-clean.csv\")\n\nRows: 60843 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (3): Sex, Race, ScoreText\ndbl  (4): Person_ID, Age, RawScore, DecileScore\ndate (1): DateOfBirth\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Boxplot for RawScore\nboxplot(compas_scores_clean$RawScore, main=\"Boxplot of Raw Scores\", \n        ylab=\"Raw Score\", xlab=\"\")\n\n\n\n# Boxplot for DecileScore\nboxplot(compas_scores_clean$DecileScore, main=\"Boxplot of Decile Scores\", \n        ylab=\"Decile Score\", xlab=\"\")\n\n\n\n\nThe box plot of the Raw Scores shows a wide range in values, suggesting a high level of variability among the scores. The median value is slightly above zero, and there is a notable presence of high outliers, indicating that some scores are significantly higher than the majority. The spread of scores within the interquartile range is large, pointing to a substantial dispersion among the middle 50% of data points. In contrast, there are no outliers on the lower side, which suggests that the lower scores are more closely packed together without extreme low values.\nOn the other hand, the box plot for the Decile Scores presents a more symmetrical distribution, with a median value around the midpoint of the score range. This plot is characterized by a narrower interquartile range, indicating less variation among the central half of the scores compared to the Raw Scores. The absence of significant outliers in the Decile Score distribution suggests a more uniform scoring scale, possibly indicating a methodical categorization into deciles. This could reflect a normalizing process, which aims to distribute the scores more evenly across a predetermined scale."
  },
  {
    "objectID": "posts/2024-02-28-post-1/post-1.html",
    "href": "posts/2024-02-28-post-1/post-1.html",
    "title": "Post 1: Dataset Description",
    "section": "",
    "text": "Data Set 1: COMPAS Recidivism Racial Bias\nDataset link here\nDescription here\nThis dataset is collected by ProPublica in 2013 and 2014, from the Broward County Sheriff’s Office in Florida. Dataset consists of 11,757 individuals’ COMPAS(Correctional Offender Management Profiling for Alternative Sanctions) score, which is a popular metric used by judges and officers to determine the likelihood of someone reoffending (recidivism). The data consists of RawScore, DecileScore and ScoreText that tells us about an individual’s COMPAS score. Each record also consists of individual’s sex, race, legal status, supervision level status, which are valuable information for our analysis on the racial difference and sex difference on the bias in COMPAS score used by judicial world.\n\n\nData Set 2: Iowa Probation Recidivism Status\nThis dataset contains deidentified case level records of individuals starting probation supervision in the community. Data begins with the FY 2016 cohort. It also provides an individual’s status at three years to assess whether probation was successful or whether the individual was reincarcerated. The dataset appears to detail recidivism among individuals released from prison, focusing on various demographic, legal, and post-release supervisory characteristics. The following are the definition on main variables in each column:\n\nRace: The individual’s race or ethnicity.\nSex: The individual’s biological sex.\nAge: The individual’s age at start of probation.\nCohort Fiscal Year: The fiscal year the individual began probation. The fiscal year runs from July 1 through June 30, and is labeled for the calendar year that it ends.\nReport Fiscal Year: The fiscal year in which probation is deemed successful. The fiscal year runs from July 1 through June 30, and is labeled for the calendar year that it ends.\nSupervision Start Date: Start date of supervision, or earliest start date of concurrent or overlapping sentences.\nSupervision End Date: End date of supervision, or latest end date of concurrent or overlapping sentences.\nPrison Supervision Start Date: Start date of prison supervision where the individual was incarcerated. Null if the individual was not incarcerated.\nPrison Supervision End Date: End date of prison supervision where the individual was incarcerated. Null if the individual was not incarcerated.\nOffense Date: The date of the offense resulting in the individual’s incarceration. Null where the individual was not incarcerated.\nSurvival Time (Days): Provides the number of days the individual was in the community before being incarcerated. Null where the individual was not incarcerated.\nSurvival Time (Months): Provides the number of months (days/30) the individual was in the community before being incarcerated. Null where the individual was not incarcerated.\nSupervision Level: Supervision level assigned to the individual. Options include Levels 1-5. Level 0 indicates risk assessment has not been conducted for the individual.\n\nThe dataset is in a csv file, so it is able to load and clean. From the dataset, we want to explore on the question that are there disparities in recidivism rates among racial-ethnic groups when considering the supervising district?\n\n\nData Set 3: IPUMS CPS COVID-19 Economic Impact Data\nDataset link here\nThis is a cross sectional dataset of data collected from the International Public Use Microdata Supplement’s current population survey. There are a plethora of both person and household level variables to choose from but we have decided to focus on the covid related and demographic variables for the purposes of our analysis.\nThe variables are as follows:\n\nCOVIDTELEW: Indicates if the respondent worked remotely for pay due to COVID-19\nCOVIDUNAW: Indicates if the respondent was unable to work due to COVID-19\nCOVIDPAID: Indicates if the respondent recieved pay for hours not worked due to COVID-19\nCOVIDLOOK: Indicates if COVID-19 prevented the respondent from looking for work\nCOVIDMED: Indicates if the respondent was unable to get needed medical care for a condition other can COVID-19 due to COVID-19\nRACE: The respondents race\n\nFrom IPUMS we were able to obtain a csv file containing data from monthly samples between May 2020 and September 2022. After successfully loading the data into R, the row count indicates that there are 3,035,625 observations in the dataset. With this data, we plan to analyze the impact of COVID-19 on economic stability among different racial groups. Thus, the main question is among different racial groups, which were those most disproportionately affected? Also, the challenge is incomplete data or missing values, which can skew results and lead to inaccurate conclusions. Ensuring data quality and completeness is a significant challenge."
  },
  {
    "objectID": "posts/2023-12-20-examples/examples.html",
    "href": "posts/2023-12-20-examples/examples.html",
    "title": "Examples",
    "section": "",
    "text": "Here are some examples of changing the size of a figure.\n\nplot(1:10)\n\n\n\n\n\n\n\n\n\nplot(1:10)\n\n\n\n\nWe can also specify column: screen and out-width: 100% so that the figure will fill the screen. plot in the svg vector graphics file format.\n\nlibrary(ggplot2)\nggplot(pressure, aes(x = temperature, y = pressure)) + geom_point()"
  },
  {
    "objectID": "posts/2023-12-20-examples/examples.html#figure-sizing",
    "href": "posts/2023-12-20-examples/examples.html#figure-sizing",
    "title": "Examples",
    "section": "",
    "text": "Here are some examples of changing the size of a figure.\n\nplot(1:10)\n\n\n\n\n\n\n\n\n\nplot(1:10)\n\n\n\n\nWe can also specify column: screen and out-width: 100% so that the figure will fill the screen. plot in the svg vector graphics file format.\n\nlibrary(ggplot2)\nggplot(pressure, aes(x = temperature, y = pressure)) + geom_point()"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This comes from the file about.qmd.\nThis is a website for the final project for MA[46]15 Data Science with R by Team TEAMNAME. The members of this team are below."
  },
  {
    "objectID": "about.html#henry-price",
    "href": "about.html#henry-price",
    "title": "About",
    "section": "Henry Price",
    "text": "Henry Price\nHenry is a junior majoring in data science with a minor in economics. github.com/hrpri"
  },
  {
    "objectID": "about.html#peizi-wang",
    "href": "about.html#peizi-wang",
    "title": "About",
    "section": "Peizi Wang",
    "text": "Peizi Wang\nPeizi Wang is a senior majoring Economics & Mathematics with a minor in Computer Science. github.com/Danielpzw"
  },
  {
    "objectID": "about.html#jiaqi-wei",
    "href": "about.html#jiaqi-wei",
    "title": "About",
    "section": "Jiaqi Wei",
    "text": "Jiaqi Wei\nJiaqi Wei is a senior majoring in Econ & Math, minoring in CS. Github User name: jackiiiiew."
  },
  {
    "objectID": "about.html#qiuting-he",
    "href": "about.html#qiuting-he",
    "title": "About",
    "section": "Qiuting He",
    "text": "Qiuting He\nQiuting He is a junior majoring in Econ & Math. Github User Name: QiutingH"
  },
  {
    "objectID": "about.html#ruihang-liu",
    "href": "about.html#ruihang-liu",
    "title": "About",
    "section": "Ruihang Liu",
    "text": "Ruihang Liu\nRuihang Liu is a senior majoring in Computer Science. Here is his github link.\n\n\nAbout this Template.\nThis is based off of the standard Quarto website template from RStudio (2023.09.0 Build 463)."
  },
  {
    "objectID": "big_picture.html",
    "href": "big_picture.html",
    "title": "Big Picture",
    "section": "",
    "text": "This comes from the file big_picture.Rmd.\nThink of this page as your 538/Upshot style article. This means that you should try to tell a story through the data and your analysis. Read articles from those sites and similar sites to get a feeling for what they are like. Try to write in the style of a news or popular article. Importantly, this pge should be geared towards the general public. You shouldn’t assume the reader understands how to interpret a linear regression. Focus on interpretation and visualizations."
  },
  {
    "objectID": "big_picture.html#rubric-on-this-page",
    "href": "big_picture.html#rubric-on-this-page",
    "title": "Big Picture",
    "section": "Rubric: On this page",
    "text": "Rubric: On this page\nYou will\n\nTitle\n\nYour big picture page should have a creative/click-bait-y title/headline that provides a hint about your thesis.\n\nClarity of Explanation\n\nYou should have a clear thesis/goal for this page. What are you trying to show? Make sure that you explain your analysis in detail but don’t go into top much mathematics or statistics. The audience for this page is the general public (to the extent possible). Your thesis should be a statement, not a question.\nEach figure should be very polished and also not too complicated. There should be a clear interpretation of the figure so the figure has a clear purpose. Even something like a histogram can be difficult to interpret for non-experts.\n\nCreativity\n\nDo your best to make things interesting. Think of a story. Think of how each part of your analysis supports the previous part or provides a different perspective.\n\nThis page should be self-contained.\n\nNote: This page should have no code visible, i.e. use #| echo: FALSE."
  },
  {
    "objectID": "big_picture.html#rubric-other-components",
    "href": "big_picture.html#rubric-other-components",
    "title": "Big Picture",
    "section": "Rubric: Other components",
    "text": "Rubric: Other components\n\nInteractive\nYou will also be required to make an interactive dashboard like this one.\nYour Big Data page should include a link to an interactive dashboard. The dashboard should be created either using Shiny or FlexDashboard (or another tool with professor’s approval). This interactive component should in some way support your thesis from your big picture page. Good interactives often provide both high-level understanding of the data while allowing a user to investigate specific scenarios, observations, subgroups, etc.\n\nQuality and ease of use of the interactive components. Is it clear what can be explored using your interactive components? Does it enhance and reinforce your conclusions from the Big Picture? Plotly with default hover text will get no credit. Be creative!\n\n\n\nVideo Recording\nMake a video recording (probably using Zoom) demonstrating your interactive components. You should provide a quick explanation of your data and demonstrate some of the conclusions from your EDA. This video should be no longer than 4 minutes. Include a link to your video (and password if needed) in your README.md file on your Github repository. You are not required to provide a link on the website. This can be presented by any subset of the team members.\n\n\nRest of the Site\nFinally, here are important things to keep in mind for the rest of the site.\nThe main title of your page is informative. Each post has an author/description/informative title. All lab required posts are present. Each page (including the home page) has a nice featured image associated with it. Your about page is up to date and clean. You have removed the generic posts from the initial site template."
  }
]