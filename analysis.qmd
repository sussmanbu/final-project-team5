---
editor: 
  markdown: 
    wrap: sentence
title: "Analysis"
description: "Here we provide a detailed analysis using more sophisticated statistics techniques."
toc: true
draft: false
---

```{r, echo=FALSE, message=FALSE, warning= FALSE, results='hide'}
# Install and load stargazer if not already installed
if (!require(gtsummary)) install.packages("gtsummary")
library(gtsummary)
```

```{r, echo=FALSE, message=FALSE, warning= FALSE, results='hide'}
library(tidyverse)
library(pROC)
library(caret)

iowa_data <- read_csv(here::here("dataset", "Iowa_Probation_Recidivism_Status_20240403.csv"), show_col_types = FALSE)
iowa_data_clean <- read_csv(here::here("dataset", "iowa-data-clean.csv"), show_col_types = FALSE)
new_compas <- read_csv(here::here("dataset", "compas-scores-two-years-violent.csv"), show_col_types = FALSE)
compas_two_years_violent <- read_csv(here::here("dataset", "compas-scores-two-years-violent.csv"), show_col_types = FALSE)
compas_scores_clean <- read_csv(here::here("dataset", "compas-scores-clean.csv"), show_col_types = FALSE)
new_compas_clean <- read_csv(here::here("dataset", "new-compas-clean.csv"), show_col_types = FALSE)
combined_data <-  read_csv(here::here("dataset", "combined-data.csv"), show_col_types = FALSE)
```

```{r Data cleaning for compas_two_years_violent, echo=FALSE, message=FALSE, warning= FALSE, results='hide'}
# rename decile_score name (weird because of the index)
colnames(compas_two_years_violent)[which(colnames(compas_two_years_violent) == "decile_score...40")] <- "decile_score"

# keep only reletive fields
compas_two_years_violent <- compas_two_years_violent  %>%
  select(sex, age, race, decile_score, score_text, reincarcerated)

# Delete records with decile_score = -1
compas_two_years_violent <- compas_two_years_violent %>%
  filter(decile_score != -1)
```

# Investigating the COMPAS Score: Unraveling Recidivism Patterns

## Introduction

In the intricate landscape of criminal justice, the **COMPAS (Correctional Offender Management Profiling for Alternative Sanctions)** score stands as a pivotal metric.
Judges and law enforcement officers rely on it to assess the likelihood of an individual reoffendingâ€”essentially predicting their propensity to commit future crimes.
But behind this seemingly objective tool lies a web of complexities, biases, and ethical dilemmas.

The following data analysis endeavors to shed light on the relationship between the COMPAS score and several key factors: **ethnic race, sex, and age**.
By delving into this trove of information, the analysis aims to unravel patterns, expose potential disparities, and contribute to a more informed discourse on recidivism.

## The Motivation

1.  **Justice or Prejudice?**\
    The COMPAS score, while ostensibly neutral, has faced scrutiny for potential racial and gender biases.
    Are certain demographics disproportionately labeled as high-risk offenders?
    This analysis seeks to answer this critical question.

2.  **Ground Truth vs. Prediction:**\
    The dataset from ProPublica not only includes the COMPAS score but also tracks whether individuals have actually reoffended.
    Comparing the ground truth outcomes with the predicted scores allows for an assessment of the model's accuracy and the uncovering of any discrepancies.

## Modeling and Inference

### Justice or Prejudice?

One of the most pressing concerns surrounding the COMPAS score is the potential for bias against certain demographic groups, which could perpetuate systemic discrimination and exacerbate existing disparities within the criminal justice system.
The analysis uncovered troubling evidence of such biases within the dataset.

The distribution of DecileScores, which represent normalized COMPAS scores ranging from 0 (lowest risk) to 10 (highest risk), across racial groups reveals stark disparities.

```{r, echo=FALSE, message=FALSE, warning= FALSE, results='hide'}
ggplot(compas_scores_clean, aes(x=Race, y=DecileScore)) +
  geom_boxplot() +
  labs(title="Distribution of DecileScores by Race",
       x="Race",
       y="DecileScore") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45))
```

As this figure illustrates, African-Americans tend to have significantly higher median decile scores compared to other races like Caucasian or Asian.
In addition, African-American is one of the only 2 minority group that does NOT have the highest score (10) as the outlier, with the other one being Native American.

This distribution raises grave concerns about the fairness and equity of the COMPAS algorithm.
If individuals from particular racial backgrounds are systematically labeled as higher-risk offenders, it could lead to harsher sentencing decisions, increased rates of incarceration, and a perpetuation of the vicious cycle of marginalization and recidivism.

Further examination of the reincarceration rates by sex and race raises additional concerns about the fairness and accuracy of the COMPAS algorithm.
The analysis revealed that the majority of individuals, regardless of their demographic characteristics, did not reoffend or become reincarcerated.

```{r, echo=FALSE, message=FALSE, warning= FALSE, results='hide'}
ggplot(combined_data, aes(x = sex, fill = reincarcerated)) + geom_bar(position = "fill") +
  ggtitle("Reincarceration Rate by Sex") + ylab("Proportion")
ggplot(combined_data, aes(x = race, fill = reincarcerated)) + geom_bar(position = "fill") +
  ggtitle("Reincarceration Rate by Race") + ylab("Proportion") + theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

This finding calls into question the validity of assigning high-risk scores to a substantial portion of the population, as it may lead to undue consequences and perpetuate cycles of marginalization.
Specifically, for [**only the violent cases**]{.underline} in the Florida dataset, individuals labeled as "high" risk by the COMPAS algorithm (decile scores of 8-10) had a reoffense rate of only 46.69%.
Meanwhile, those classified as "medium" risk (decile scores of 5-7) had a reoffense rate of 27.23%.
These figures raise concerns about the high-risk threshold set by the COMPAS tool, as a 46.69% reoffense rate for the "high" risk group may not justify the potential consequences associated with such a label, particularly when considering the low overall reincarceration rates observed in our data.

```{r, echo=FALSE, message=FALSE, warning= FALSE, results='hide'}
reoffense_rates <- compas_two_years_violent %>%
  group_by(score_text) %>%
  summarize(reoffense_rate = mean(reincarcerated))

# Print the result
print(reoffense_rates)
```

The concerning disparities shown in the distribution of COMPAS scores naturally raise questions about the validity and accuracy of the algorithm's risk predictions.
While the disproportionately higher risk assignments for certain minority groups are undoubtedly problematic from a fairness perspective, an equally crucial inquiry is whether these scores align with **actual recidivism outcomes**.
Do the COMPAS scores effectively capture the ground truth of an individual's likelihood of reoffending, or are they plagued by systematic biases that perpetuate existing prejudices?
To address this critical question, the analysis turns to a direct comparison between the COMPAS risk predictions and the observed reoffending rates across different racial groups.

### Ground Truth vs. Prediction

To further assess the COMPAS algorithm's performance and potential biases, a predictive model was developed using the combined data from both Florida and Iowa.
The approach involved building a logistic regression model that predicted the binary outcome of reincarceration based on predictor variables such as sex, age, race, and state.
The model was trained by setting the reference levels for categorical variables (sex, race, and state) to the categories with the most data points (Male, White, and Iowa, respectively).

The model's performance was evaluated using the ROC (Receiver Operating Characteristic) curve, as shown in the image.
The area under the curve (AUC) of 0.6106 indicates a moderate level of predictive performance, albeit with room for improvement.

```{r, echo=FALSE, message=FALSE, warning= FALSE, results='hide'}
combined_data$sex <- factor(combined_data$sex)
combined_data$sex <- relevel(combined_data$sex, ref = "Male")
combined_data$race <- factor(combined_data$race)
combined_data$race <- relevel(combined_data$race, ref = "White")
combined_data$state <- factor(combined_data$state)
combined_data$state <- relevel(combined_data$state, ref = "Iowa")
model <- glm(reincarcerated ~ sex + age + race + state, data = combined_data, family = "binomial")

predicted_probabilities <- predict(model, newdata = combined_data, type = "response")
roc_curve <- roc(response = combined_data$reincarcerated, predictor = predicted_probabilities)
plot(roc_curve, main = "ROC Curve")
auc(roc_curve)
```

To better understand the model's predictions, the coefficients for each predictor variable were examined.
According to the model, factors such as being American Indian or Alaska Native, Black, or from the state of Florida were associated with higher probabilities of reincarceration compared to the respective reference categories (White and Iowa).

```{r, echo=FALSE, message=FALSE, warning= FALSE}
# Generate the summary table
model_summary <- model %>%
  tbl_regression() %>%
  add_global_p() %>%
  bold_labels() %>%
  italicize_levels()

# Print the summary table
model_summary
```

It's important to note that these findings contrast with the racial biases observed in the COMPAS scores.
While the COMPAS scores exhibited a clear bias against African-Americans, the model and the ground truth data both suggested that American Indian or Alaska Native individuals had the highest likelihood of reoffending, followed by African-Americans.
This highlights the divergent patterns of bias present in the COMPAS algorithm compared to the observed recidivism rates in the analysis.

Furthermore, examination of the proportion of different races that reoffended in each state revealed that Black individuals were not the most likely to reoffend in either Florida or Iowa.

```{r, echo=FALSE, message=FALSE, warning= FALSE, results='hide'}
proportion_data <- combined_data %>%
  group_by(state, race) %>%
  summarise(Reoffence_Proportion = mean(reincarcerated, na.rm = TRUE)) %>%
  ungroup()

# Plot the proportions
ggplot(proportion_data, aes(x = race, y = Reoffence_Proportion, fill = race)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  facet_wrap(~ state) +
  labs(title = "Proportion of Different Races Reoffended in Each State",
       x = "Race",
       y = "Proportion of Reoffence") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, hjust = 1)) 
```

These results underscore the importance of critically evaluating and calibrating risk assessment tools like COMPAS to ensure that they accurately reflect real-world patterns and do not perpetuate or amplify existing biases against certain racial or ethnic groups.
The findings highlight the complex interplay of factors that influence recidivism rates and the potential for data-driven models to exhibit biases or inaccuracies if not carefully constructed and validated.
While the model captures some underlying patterns, it is crucial to acknowledge that historical data on recidivism rates should not be blindly extrapolated to make sweeping generalizations about entire racial or ethnic groups.
Just because certain groups may have higher observed reoffending rates in the past does not justify assigning elevated risk scores or harsher sentences to all individuals from those backgrounds.
Such an approach would only perpetuate cycles of systemic discrimination and undermine the principles of equal justice under the law.

The analysis underscores the need for a more nuanced and individualized approach to risk assessment, one that accounts for the multitude of factors that influence an individual's likelihood of reoffending.
While data-driven models can provide valuable insights, they must be carefully calibrated, validated, and complemented with human judgment and a deep understanding of the underlying societal dynamics at play.
Furthermore, ongoing efforts to address systemic biases, improve data quality, and explore alternative modeling approaches are crucial for developing more equitable and effective risk assessment tools.
