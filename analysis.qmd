---
editor: 
  markdown: 
    wrap: sentence
title: "Analysis"
description: "Here we provide a detailed analysis using more sophisticated statistics techniques."
toc: true
draft: false
---

![](https://upload.wikimedia.org/wikipedia/commons/7/77/Pebbleswithquarzite.jpg)

This comes from the file `analysis.qmd`.

We describe here our detailed data analysis.
This page will provide an overview of what questions you addressed, illustrations of relevant aspects of the data with tables and figures, and a statistical model that attempts to answer part of the question.
You'll also reflect on next steps and further analysis.

The audience for this page is someone like your class mates, so you can expect that they have some level of statistical and quantitative sophistication and understand ideas like linear and logistic regression, coefficients, confidence intervals, overfitting, etc.

While the exact number of figures and tables will vary and depend on your analysis, you should target around 5 to 6.
An overly long analysis could lead to losing points.
If you want you can link back to your blog posts or create separate pages with more details.

The style of this paper should aim to be that of an academic paper.
I don't expect this to be of publication quality but you should keep that aim in mind.
Avoid using "we" too frequently, for example "We also found that ...".
Describe your methodology and your findings but don't describe your whole process.

### Example of loading data

The code below shows an example of loading the loan refusal data set (which you should delete at some point).

library(tidyverse) print(getwd()) data \<- read_csv(here::here("dataset/loan_refusal_clean.csv")) load(here::here("dataset/loan_refusal.RData")) print(ls())

## Note on Attribution

In general, you should try to provide links to relevant resources, especially those that helped you.
You don't have to link to every StackOverflow post you used but if there are explainers on aspects of the data or specific models that you found helpful, try to link to those.
Also, try to link to other sources that might support (or refute) your analysis.
These can just be regular hyperlinks.
You don't need a formal citation.

If you are directly quoting from a source, please make that clear.
You can show quotes using `>` like this

```         
> To be or not to be.
```

> To be or not to be.

------------------------------------------------------------------------

## Rubric: On this page

You will

-   Introduce what motivates your Data Analysis (DA)
    -   Which variables and relationships are you most interested in?
    -   What questions are you interested in answering?
    -   Provide context for the rest of the page. This will include figures/tables that illustrate aspects of the data of your question.
-   Modeling and Inference
    -   The page will include some kind of formal statistical model. This could be a linear regression, logistic regression, or another modeling framework.
    -   Explain the ideas and techniques you used to choose the predictors for your model. (Think about including interaction terms and other transformations of your variables.)
    -   Describe the results of your modelling and make sure to give a sense of the uncertainty in your estimates and conclusions.
-   Explain the flaws and limitations of your analysis
    -   Are there some assumptions that you needed to make that might not hold? Is there other data that would help to answer your questions?
-   Clarity Figures
    -   Are your figures/tables/results easy to read, informative, without problems like overplotting, hard-to-read labels, etc?
    -   Each figure should provide a key insight. Too many figures or other data summaries can detract from this. (While not a hard limit, around 5 total figures is probably a good target.)
    -   Default `lm` output and plots are typically not acceptable.
-   Clarity of Explanations
    -   How well do you explain each figure/result?
    -   Do you provide interpretations that suggest further analysis or explanations for observed phenomenon?
-   Organization and cleanliness.
    -   Make sure to remove excessive warnings, hide most or all code, organize with sections or multiple pages, use bullets, etc.
    -   This page should be self-contained, i.e. provide a description of the relevant data.

------------------------------------------------------------------------

***NOTE: Everything above this should be removed before final submission.***

Load dataset ***Hide the code before submission***

```{r, echo=FALSE, message=FALSE, warning= FALSE, results='hide'}
# Install and load stargazer if not already installed
if (!require(gtsummary)) install.packages("gtsummary")
library(gtsummary)
```

```{r, echo=FALSE, message=FALSE, warning= FALSE, results='hide'}
library(tidyverse)
library(pROC)
library(caret)

iowa_data <- read_csv(here::here("dataset", "Iowa_Probation_Recidivism_Status_20240403.csv"), show_col_types = FALSE)
iowa_data_clean <- read_csv(here::here("dataset", "iowa-data-clean.csv"), show_col_types = FALSE)
new_compas <- read_csv(here::here("dataset", "compas-scores-two-years-violent.csv"), show_col_types = FALSE)
compas_two_years_violent <- read_csv(here::here("dataset", "compas-scores-two-years-violent.csv"), show_col_types = FALSE)
compas_scores_clean <- read_csv(here::here("dataset", "compas-scores-clean.csv"), show_col_types = FALSE)
new_compas_clean <- read_csv(here::here("dataset", "new-compas-clean.csv"), show_col_types = FALSE)
combined_data <-  read_csv(here::here("dataset", "combined-data.csv"), show_col_types = FALSE)
```

***Following section should be moved to data page.*** --------------

```{r Data cleaning for compas_two_years_violent}
# rename decile_score name (weird because of the index)
colnames(compas_two_years_violent)[which(colnames(compas_two_years_violent) == "decile_score...40")] <- "decile_score"

# keep only reletive fields
compas_two_years_violent <- compas_two_years_violent  %>%
  select(sex, age, race, decile_score, score_text, reincarcerated)

# Delete records with decile_score = -1
compas_two_years_violent <- compas_two_years_violent %>%
  filter(decile_score != -1)
```

----------------------------------- ***Keep below***

# Investigating the COMPAS Score: Unraveling Recidivism Patterns

## Introduction

In the intricate landscape of criminal justice, the **COMPAS (Correctional Offender Management Profiling for Alternative Sanctions)** score stands as a pivotal metric.
Judges and law enforcement officers rely on it to assess the likelihood of an individual reoffending—essentially predicting their propensity to commit future crimes.
But behind this seemingly objective tool lies a web of complexities, biases, and ethical dilemmas.

Our data analysis endeavors to shed light on the relationship between the COMPAS score and several key factors: **ethnic race, sex, and age**.
By delving into this trove of information, we aim to unravel patterns, expose potential disparities, and contribute to a more informed discourse on recidivism.

## The Motivation

1.  **Justice or Prejudice?**\
    The COMPAS score, while ostensibly neutral, has faced scrutiny for potential racial and gender biases.
    Are certain demographics disproportionately labeled as high-risk offenders?
    Our investigation seeks to answer this critical question.

    1.  Distribution of DecileScores by Race

2.  **Ground Truth vs. Prediction:**\
    Our dataset not only includes the COMPAS score but also tracks whether individuals have actually reoffended.
    By comparing these ground truth outcomes with the predicted scores, we can assess the model’s accuracy and uncover any discrepancies.

    1.  ROC

    2.  Effect of Age on Re-offending

    3.  Proportion of Different Races Reoffended in Each State

## Modeling and Inference

### Justice or Prejudice?

One of the most pressing concerns surrounding the COMPAS score is the potential for bias against certain demographic groups, which could perpetuate systemic discrimination and exacerbate existing disparities within the criminal justice system.
Our analysis uncovered troubling evidence of such biases within our dataset.

The distribution of DecileScores, which represent normalized COMPAS scores ranging from 0 (lowest risk) to 10 (highest risk), across racial groups reveals stark disparities.

```{r, echo=FALSE, message=FALSE, warning= FALSE, results='hide'}
ggplot(compas_scores_clean, aes(x=Race, y=DecileScore)) +
  geom_boxplot() +
  labs(title="Distribution of DecileScores by Race",
       x="Race",
       y="DecileScore") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45))
```

As this figure illustrates, African-Americans tend to have significantly higher median decile scores compared to other races like Caucasian or Asian.
In addition, African-American is one of the only 2 minority group that does NOT have the highest score (10) as the outlier, with the other one being Native American.

This distribution raises grave concerns about the fairness and equity of the COMPAS algorithm.
If individuals from particular racial backgrounds are systematically labeled as higher-risk offenders, it could lead to harsher sentencing decisions, increased rates of incarceration, and a perpetuation of the vicious cycle of marginalization and recidivism.

Further examination of the reincarceration rates by sex and race raises additional concerns about the fairness and accuracy of the COMPAS algorithm.
Our analysis revealed that the majority of individuals, regardless of their demographic characteristics, did not reoffend or become reincarcerated.

```{r, echo=FALSE, message=FALSE, warning= FALSE, results='hide'}
ggplot(combined_data, aes(x = sex, fill = reincarcerated)) + geom_bar(position = "fill") +
  ggtitle("Reincarceration Rate by Sex") + ylab("Proportion")
ggplot(combined_data, aes(x = race, fill = reincarcerated)) + geom_bar(position = "fill") +
  ggtitle("Reincarceration Rate by Race") + ylab("Proportion") + theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

This finding calls into question the validity of assigning high-risk scores to a substantial portion of the population, as it may lead to undue consequences and perpetuate cycles of marginalization.

Specifically, for [**only the violent cases**]{.underline} in the Florida dataset, individuals labeled as "high" risk by the COMPAS algorithm (decile scores of 8-10) had a reoffense rate of only 46.69%.
Meanwhile, those classified as "medium" risk (decile scores of 5-7) had a reoffense rate of 27.23%.
These figures raise concerns about the high-risk threshold set by the COMPAS tool, as a 46.69% reoffense rate for the "high" risk group may not justify the potential consequences associated with such a label, particularly when considering the low overall reincarceration rates observed in our data.

```{r, echo=FALSE, message=FALSE, warning= FALSE, results='hide'}
reoffense_rates <- compas_two_years_violent %>%
  group_by(score_text) %>%
  summarize(reoffense_rate = mean(reincarcerated))

# Print the result
print(reoffense_rates)
```

Those concerning disparities shown in the distribution of COMPAS scores naturally raise questions about the validity and accuracy of the algorithm's risk predictions.
While the disproportionately higher risk assignments for certain minority groups are undoubtedly problematic from a fairness perspective, an equally crucial inquiry is whether these scores align with **actual recidivism outcomes**.
Do the COMPAS scores effectively capture the ground truth of an individual's likelihood of reoffending, or are they plagued by systematic biases that perpetuate existing prejudices?
To address this critical question, we turn our analysis to a direct comparison between the COMPAS risk predictions and the observed reoffending rates across different racial groups.

### Ground Truth vs. Prediction

To further assess the COMPAS algorithm's performance and potential biases, we developed our own predictive model using the combined data from both Florida and Iowa.
Our approach involved building a logistic regression model that predicted the binary outcome of reincarceration based on predictor variables such as sex, age, race, and state.
The model was trained by setting the reference levels for categorical variables (sex, race, and state) to the categories with the most data points (Male, White, and Iowa, respectively).

The model's performance was evaluated using the ROC (Receiver Operating Characteristic) curve, as shown in the image.
The area under the curve (AUC) of 0.6106 indicates a moderate level of predictive performance, albeit with room for improvement.

```{r, echo=FALSE, message=FALSE, warning= FALSE, results='hide'}
combined_data$sex <- factor(combined_data$sex)
combined_data$sex <- relevel(combined_data$sex, ref = "Male")
combined_data$race <- factor(combined_data$race)
combined_data$race <- relevel(combined_data$race, ref = "White")
combined_data$state <- factor(combined_data$state)
combined_data$state <- relevel(combined_data$state, ref = "Iowa")
model <- glm(reincarcerated ~ sex + age + race + state, data = combined_data, family = "binomial")

predicted_probabilities <- predict(model, newdata = combined_data, type = "response")
roc_curve <- roc(response = combined_data$reincarcerated, predictor = predicted_probabilities)
plot(roc_curve, main = "ROC Curve")
auc(roc_curve)
```

To better understand the model's predictions, we examined the coefficients for each predictor variable.

```{r, echo=FALSE, message=FALSE, warning= FALSE}
# Generate the summary table
model_summary <- model %>%
  tbl_regression() %>%
  add_global_p() %>%
  bold_labels() %>%
  italicize_levels()

# Print the summary table
model_summary
```

According to the model, factors such as being American Indian or Alaska Native, Black, or from the state of Florida were associated with higher probabilities of reincarceration compared to the respective reference categories (White and Iowa).

It's important to note that these findings contrast with the racial biases observed in the COMPAS scores.
While the COMPAS scores exhibited a clear bias against African-Americans, our model and the ground truth data both suggested that American Indian or Alaska Native individuals had the highest likelihood of reoffending, followed by African-Americans.
This highlights the divergent patterns of bias present in the COMPAS algorithm compared to the observed recidivism rates in our analysis.

Furthermore, our examination of the proportion of different races that reoffended in each state revealed that Black individuals were not the most likely to reoffend in either Florida or Iowa.

```{r, echo=FALSE, message=FALSE, warning= FALSE, results='hide'}
proportion_data <- combined_data %>%
  group_by(state, race) %>%
  summarise(Reoffence_Proportion = mean(reincarcerated, na.rm = TRUE)) %>%
  ungroup()

# Plot the proportions
ggplot(proportion_data, aes(x = race, y = Reoffence_Proportion, fill = race)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  facet_wrap(~ state) +
  labs(title = "Proportion of Different Races Reoffended in Each State",
       x = "Race",
       y = "Proportion of Reoffence") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, hjust = 1)) 
```

These results underscore the importance of critically evaluating and calibrating risk assessment tools like COMPAS to ensure that they accurately reflect real-world patterns and do not perpetuate or amplify existing biases against certain racial or ethnic groups.
Those findings highlight the complex interplay of factors that influence recidivism rates and the potential for data-driven models to exhibit biases or inaccuracies if not carefully constructed and validated.
While our model captures some underlying patterns, it is crucial to acknowledge that historical data on recidivism rates should not be blindly extrapolated to make sweeping generalizations about entire racial or ethnic groups.
Just because certain groups may have higher observed reoffending rates in the past does not justify assigning elevated risk scores or harsher sentences to all individuals from those backgrounds.
Such an approach would only perpetuate cycles of systemic discrimination and undermine the principles of equal justice under the law.

Our analysis underscores the need for a more nuanced and individualized approach to risk assessment, one that accounts for the multitude of factors that influence an individual's likelihood of reoffending.
While data-driven models can provide valuable insights, they must be carefully calibrated, validated, and complemented with human judgment and a deep understanding of the underlying societal dynamics at play.
Furthermore, ongoing efforts to address systemic biases, improve data quality, and explore alternative modeling approaches are crucial for developing more equitable and effective risk assessment tools.
