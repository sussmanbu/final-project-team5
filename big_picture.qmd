---
title: "Big Picture"
description: ""
toc: true
draft: FALSE
---

# ![](images/WechatIMG166.jpg)Unveiling Bias: A Deep Dive into the COMPAS Recidivism Scores

The use of algorithmic scoring in criminal justice, specifically the COMPAS (Correctional Offender Management Profiling for Alternative Sanctions) score, has been touted as a way to modernize and streamline sentencing processes. This score is meant to predict the likelihood that an individual will reoffend. However, beneath the digital facade, concerns about bias and fairness persist. Our exploration of the relationship between demographics and COMPAS score provides insights into how these scores correlate with age, sex, and race, highlighting potential biases that could influence judicial decisions and outcomes.

## Sex and Race Under the Microscope

```{r echo = FALSE, message=FALSE}
library(tidyverse)
library(MASS)
compas_scores_clean <- read_csv("dataset/compas-scores-clean.csv")

ggplot(compas_scores_clean, aes(x=Sex, y=DecileScore)) +
  geom_boxplot() +
  labs(title="Distribution of DecileScores by Sex",
       x="Sex",
       y="DecileScore") +
  theme_minimal()
```

First, let's examine how decile scores distribute across different genders and races. The above figure indicates a generally similar median score for both males and females, though males display a slightly wider range in scores. This could imply a greater variance in how men are assessed, potentially impacting their legal outcomes more diversely than women.

```{r echo = FALSE}

df <- compas_scores_clean %>% 
  mutate(Race = case_when(
      Race %in% c("African-American", "African-Am") ~ "African-American",
      TRUE ~ Race
    )) %>% 
  mutate(Age_Bin = cut(Age, 
                               breaks = seq(10, 100, by = 10), 
                               labels = c("10-19", "20-29", "30-39", "40-49", "50-59", "60-69", "70-79", "80-89", "90-99"))) %>%
  group_by(Age_Bin, Race) %>% 
  mutate(Avg_Score = ave(DecileScore)) %>% 
  view()

ggplot(df, aes(x=Race, y=DecileScore)) +
  geom_boxplot() +
  labs(title="Distribution of DecileScores by Race",
       x="Race",
       y="DecileScore") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Race, however, tells a more concerning story. The distribution of scores by race reveals that African Americans typically receive higher decile scores compared to other races, hinting at a racial bias embedded within the scoring algorithm. This finding raises crucial ethical questions about the deployment of tools such as COMPAS in a justice system that should be blind to color.

## Age, Recidivism, and the Algorithm

```{r echo = FALSE, warning=FALSE}
df %>% 
  distinct(Age_Bin, Race, Avg_Score) %>% 
  ggplot(aes(x = as.factor(Age_Bin), y = Avg_Score)) +
    geom_col(fill = "blue") +
    ggtitle("Score Distribution by Age and Race") +
    xlab("Age") +
    ylab("Average Score") +
    facet_wrap(~ Race, scales = "free_y") +  # Faceting by race
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Age also plays a significant role in the COMPAS assessments. Younger individuals tend to have higher scores, which gradually decrease with age. This trend is consistent across all racial groups but is more pronounced in some than others, suggesting that age-related biases could intersect with racial biases to compound the effects of an already flawed system.

## Exploring State-Specific and Racial Impacts on Recidivism Predictions

In order to better understand the COMPAS algorithm's implications, we extended our analysis to a logistic regression model using data from Florida and Iowa, aiming to predict the binary outcome of reincarceration based on variables like sex, age, race, and state.

![](images/clipboard-3228062840.png)

This model brings to light intriguing insights about the impact of state and race on recidivism predictions. Notably, American Indian or Alaska Native individuals, as well as those from Florida, were found to have higher probabilities of reincarceration compared to their counterparts. This is particularly compelling given that the analysis of COMPAS scores showed a different bias—predominantly against African-Americans. Furthermore, the actual data reveals that Black individuals do not hold the highest reoffense rates in either state, challenging some preconceived notions about racial patterns in recidivism.

By dissecting these dimensions, our analysis not only questions the fidelity of tools like COMPAS in reflecting true recidivism patterns but also underscores the critical need for calibrated, transparent risk assessments in the justice system. These insights advocate for a reassessment of how demographic factors are weighted in predictive models, ensuring they serve justice equitably without reinforcing biases.

## Conclusion

What does this mean for justice? Our analysis highlights potential disparities in how COMPAS scores are assigned, with troubling implications for fairness and equality in criminal sentencing. These biases could lead to harsher sentencing and higher bail amounts for demographic groups that are already disproportionately affected by the justice system.

As we reflect on these findings, it becomes clear that reliance on such algorithmic assessments without ongoing scrutiny and adjustment perpetuates existing societal inequalities under the guise of objectivity. The path forward must involve transparent, inclusive discussions about the role of technology in justice—a dialogue that prioritizes fairness over efficiency.
